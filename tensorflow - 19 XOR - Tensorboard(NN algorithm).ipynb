{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "- Tensor의 그래프를 확인\n",
    "- Tensorflow에서 동작하는 cost ftn의 최소화 과정 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From TF graph, decide which tensors you want to log\n",
    "    > w2_hist = tf.summary.histogram(\"weights2\", W2)<br>\n",
    "    > cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "2. Merge all summaries\n",
    "    > merged_summary = tf.summary.merge_all()\n",
    "3. Create writer and add graph\n",
    "    > writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    > writer.add_graph(sess.graph)  # Show the graph\n",
    "4. Run summary merge and add_summary\n",
    "    > summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})<br>\n",
    "    > writer.add_summary(summary, global_step=step)\n",
    "5. Launch Tensorboard\n",
    "    > tensorboard --logdir=./logs (anaconda 창)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7156377 [array([[ 0.7926959 ,  0.6886104 ],\n",
      "       [-1.2072834 , -0.29517072]], dtype=float32), array([[1.7177    ],\n",
      "       [0.35572484]], dtype=float32)]\n",
      "100 0.6907327 [array([[ 0.32268244, -0.23303036],\n",
      "       [-0.7743417 ,  0.8052943 ]], dtype=float32), array([[1.4608113 ],\n",
      "       [0.78415203]], dtype=float32)]\n",
      "200 0.49503163 [array([[ 1.6721692, -2.3216543],\n",
      "       [-2.2168636,  2.6561468]], dtype=float32), array([[2.8243914],\n",
      "       [2.6025808]], dtype=float32)]\n",
      "300 0.22374642 [array([[ 3.1877632, -3.7442877],\n",
      "       [-3.6972432,  4.1295667]], dtype=float32), array([[4.7004085],\n",
      "       [4.3188057]], dtype=float32)]\n",
      "400 0.12229483 [array([[ 3.9886725, -4.520833 ],\n",
      "       [-4.4841404,  4.903435 ]], dtype=float32), array([[5.8487263],\n",
      "       [5.4189944]], dtype=float32)]\n",
      "500 0.078843184 [array([[ 4.4861465, -5.0151863],\n",
      "       [-4.973251 ,  5.39077  ]], dtype=float32), array([[6.6447487],\n",
      "       [6.2020254]], dtype=float32)]\n",
      "600 0.055981167 [array([[ 4.839386 , -5.370661 ],\n",
      "       [-5.3210588,  5.7398577]], dtype=float32), array([[7.2586293],\n",
      "       [6.8132977]], dtype=float32)]\n",
      "700 0.04224272 [array([[ 5.111045 , -5.645957 ],\n",
      "       [-5.5889034,  6.009811 ]], dtype=float32), array([[7.7626452],\n",
      "       [7.3183374]], dtype=float32)]\n",
      "800 0.033227302 [array([[ 5.3308954, -5.8696966],\n",
      "       [-5.8059134,  6.2290907]], dtype=float32), array([[8.193123],\n",
      "       [7.751217]], dtype=float32)]\n",
      "900 0.026933454 [array([[ 5.515177 , -6.057749 ],\n",
      "       [-5.9879947,  6.413374 ]], dtype=float32), array([[8.57083 ],\n",
      "       [8.131825]], dtype=float32)]\n",
      "1000 0.022333965 [array([[ 5.67365  , -6.219753 ],\n",
      "       [-6.1447105,  6.572153 ]], dtype=float32), array([[8.90876 ],\n",
      "       [8.472787]], dtype=float32)]\n",
      "1100 0.01885244 [array([[ 5.812608 , -6.3619866],\n",
      "       [-6.282229 ,  6.711584 ]], dtype=float32), array([[9.215611],\n",
      "       [8.78262 ]], dtype=float32)]\n",
      "1200 0.016142853 [array([[ 5.9363365, -6.4887395],\n",
      "       [-6.4047527,  6.8358717]], dtype=float32), array([[9.497477 ],\n",
      "       [9.0673685]], dtype=float32)]\n",
      "1300 0.013985719 [array([[ 6.0478745, -6.6030784],\n",
      "       [-6.5152693,  6.9480157]], dtype=float32), array([[9.758837],\n",
      "       [9.331477]], dtype=float32)]\n",
      "1400 0.0122359805 [array([[ 6.1494503, -6.7072563],\n",
      "       [-6.615971 ,  7.0502205]], dtype=float32), array([[10.003056],\n",
      "       [ 9.578303]], dtype=float32)]\n",
      "1500 0.010794317 [array([[ 6.242753 , -6.8029747],\n",
      "       [-6.7085137,  7.1441584]], dtype=float32), array([[10.232743],\n",
      "       [ 9.810454]], dtype=float32)]\n",
      "1600 0.009590316 [array([[ 6.32908  , -6.8915577],\n",
      "       [-6.7941732,  7.2311172]], dtype=float32), array([[10.449962],\n",
      "       [10.03    ]], dtype=float32)]\n",
      "1700 0.008573185 [array([[ 6.4094553, -6.9740477],\n",
      "       [-6.8739595,  7.312116 ]], dtype=float32), array([[10.656366],\n",
      "       [10.238612]], dtype=float32)]\n",
      "1800 0.0077051977 [array([[ 6.484699 , -7.051277 ],\n",
      "       [-6.9486804,  7.387974 ]], dtype=float32), array([[10.853316],\n",
      "       [10.437652]], dtype=float32)]\n",
      "1900 0.006957829 [array([[ 6.5554795, -7.12393  ],\n",
      "       [-7.0189905,  7.459351 ]], dtype=float32), array([[11.041933],\n",
      "       [10.628246]], dtype=float32)]\n",
      "2000 0.006309393 [array([[ 6.6223445, -7.1925664],\n",
      "       [-7.0854316,  7.5267982]], dtype=float32), array([[11.223158],\n",
      "       [10.811347]], dtype=float32)]\n",
      "2100 0.005742714 [array([[ 6.685749 , -7.2576523],\n",
      "       [-7.148453 ,  7.59077  ]], dtype=float32), array([[11.397784],\n",
      "       [10.987764]], dtype=float32)]\n",
      "2200 0.005244485 [array([[ 6.7460775, -7.319577 ],\n",
      "       [-7.208433 ,  7.6516523]], dtype=float32), array([[11.566492],\n",
      "       [11.158178]], dtype=float32)]\n",
      "2300 0.0048038983 [array([[ 6.8036537, -7.3786774],\n",
      "       [-7.2656927,  7.7097683]], dtype=float32), array([[11.729868],\n",
      "       [11.323187]], dtype=float32)]\n",
      "2400 0.004412344 [array([[ 6.8587594, -7.435237 ],\n",
      "       [-7.320504 ,  7.765398 ]], dtype=float32), array([[11.888419],\n",
      "       [11.483295]], dtype=float32)]\n",
      "2500 0.004062689 [array([[ 6.91163  , -7.489502 ],\n",
      "       [-7.3731093,  7.818782 ]], dtype=float32), array([[12.042592],\n",
      "       [11.638964]], dtype=float32)]\n",
      "2600 0.0037491736 [array([[ 6.962477, -7.541683],\n",
      "       [-7.423709,  7.870127]], dtype=float32), array([[12.19277 ],\n",
      "       [11.790581]], dtype=float32)]\n",
      "2700 0.0034669796 [array([[ 7.0114794, -7.5919704],\n",
      "       [-7.4724846,  7.919617 ]], dtype=float32), array([[12.339302 ],\n",
      "       [11.9384985]], dtype=float32)]\n",
      "2800 0.003212058 [array([[ 7.0587955, -7.6405253],\n",
      "       [-7.5195923,  7.9674115]], dtype=float32), array([[12.482494],\n",
      "       [12.083018]], dtype=float32)]\n",
      "2900 0.0029809962 [array([[ 7.104568 , -7.687491 ],\n",
      "       [-7.5651712,  8.013649 ]], dtype=float32), array([[12.622612],\n",
      "       [12.224427]], dtype=float32)]\n",
      "3000 0.0027709822 [array([[ 7.1489196, -7.7329946],\n",
      "       [-7.609344 ,  8.0584545]], dtype=float32), array([[12.759907],\n",
      "       [12.362965]], dtype=float32)]\n",
      "3100 0.002579568 [array([[ 7.1919622, -7.777151 ],\n",
      "       [-7.652218 ,  8.101942 ]], dtype=float32), array([[12.894589],\n",
      "       [12.498854]], dtype=float32)]\n",
      "3200 0.0024046064 [array([[ 7.233792 , -7.8200593],\n",
      "       [-7.693892 ,  8.144206 ]], dtype=float32), array([[13.026862 ],\n",
      "       [12.6322975]], dtype=float32)]\n",
      "3300 0.0022443123 [array([[ 7.274499 , -7.8618126],\n",
      "       [-7.7344537,  8.185339 ]], dtype=float32), array([[13.156905],\n",
      "       [12.763471]], dtype=float32)]\n",
      "3400 0.0020971396 [array([[ 7.314162, -7.902492],\n",
      "       [-7.773981,  8.225419]], dtype=float32), array([[13.284877],\n",
      "       [12.892542]], dtype=float32)]\n",
      "3500 0.001961769 [array([[ 7.352852 , -7.9421716],\n",
      "       [-7.812545 ,  8.264521 ]], dtype=float32), array([[13.410925],\n",
      "       [13.019661]], dtype=float32)]\n",
      "3600 0.0018369715 [array([[ 7.3906364, -7.980915 ],\n",
      "       [-7.8502088,  8.302705 ]], dtype=float32), array([[13.535187],\n",
      "       [13.144961]], dtype=float32)]\n",
      "3700 0.0017217281 [array([[ 7.4275703, -8.018786 ],\n",
      "       [-7.8870325,  8.340034 ]], dtype=float32), array([[13.657784],\n",
      "       [13.26857 ]], dtype=float32)]\n",
      "3800 0.0016151398 [array([[ 7.463711 , -8.055838 ],\n",
      "       [-7.9230676,  8.376559 ]], dtype=float32), array([[13.778829],\n",
      "       [13.390599]], dtype=float32)]\n",
      "3900 0.0015163682 [array([[ 7.4991055, -8.09212  ],\n",
      "       [-7.958363 ,  8.412334 ]], dtype=float32), array([[13.898424],\n",
      "       [13.511158]], dtype=float32)]\n",
      "4000 0.0014247242 [array([[ 7.5337973, -8.127679 ],\n",
      "       [-7.9929643,  8.447398 ]], dtype=float32), array([[14.016665],\n",
      "       [13.630341]], dtype=float32)]\n",
      "4100 0.0013396095 [array([[ 7.567828, -8.162559],\n",
      "       [-8.026908,  8.481797]], dtype=float32), array([[14.133643],\n",
      "       [13.748235]], dtype=float32)]\n",
      "4200 0.0012603657 [array([[ 7.6012373, -8.196796 ],\n",
      "       [-8.060234 ,  8.515567 ]], dtype=float32), array([[14.249437],\n",
      "       [13.864925]], dtype=float32)]\n",
      "4300 0.0011866036 [array([[ 7.634057, -8.230428],\n",
      "       [-8.092978,  8.548741]], dtype=float32), array([[14.364121],\n",
      "       [13.980484]], dtype=float32)]\n",
      "4400 0.0011178144 [array([[ 7.666319, -8.263484],\n",
      "       [-8.125167,  8.581354]], dtype=float32), array([[14.477767],\n",
      "       [14.094987]], dtype=float32)]\n",
      "4500 0.0010535648 [array([[ 7.698053, -8.295999],\n",
      "       [-8.156836,  8.613435]], dtype=float32), array([[14.590436],\n",
      "       [14.208499]], dtype=float32)]\n",
      "4600 0.0009935705 [array([[ 7.729288, -8.327996],\n",
      "       [-8.188007,  8.645012]], dtype=float32), array([[14.70219 ],\n",
      "       [14.321079]], dtype=float32)]\n",
      "4700 0.00093739806 [array([[ 7.760048, -8.359506],\n",
      "       [-8.218708,  8.676106]], dtype=float32), array([[14.813087],\n",
      "       [14.432786]], dtype=float32)]\n",
      "4800 0.00088485295 [array([[ 7.790355, -8.390548],\n",
      "       [-8.248958,  8.706743]], dtype=float32), array([[14.923176],\n",
      "       [14.543669]], dtype=float32)]\n",
      "4900 0.00083560665 [array([[ 7.8202324, -8.421149 ],\n",
      "       [-8.278784 ,  8.736949 ]], dtype=float32), array([[15.032508],\n",
      "       [14.653779]], dtype=float32)]\n",
      "5000 0.0007894051 [array([[ 7.849699 , -8.4513235],\n",
      "       [-8.308202 ,  8.766735 ]], dtype=float32), array([[15.141127],\n",
      "       [14.763162]], dtype=float32)]\n",
      "5100 0.000746024 [array([[ 7.8787746, -8.481094 ],\n",
      "       [-8.337231 ,  8.796127 ]], dtype=float32), array([[15.249074],\n",
      "       [14.871863]], dtype=float32)]\n",
      "5200 0.000705329 [array([[ 7.907476, -8.510482],\n",
      "       [-8.365889,  8.825144]], dtype=float32), array([[15.356389],\n",
      "       [14.979918]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 0.00066705124 [array([[ 7.935819, -8.539501],\n",
      "       [-8.39419 ,  8.853798]], dtype=float32), array([[15.463109],\n",
      "       [15.087366]], dtype=float32)]\n",
      "5400 0.00063107116 [array([[ 7.9638205, -8.568164 ],\n",
      "       [-8.422157 ,  8.882103 ]], dtype=float32), array([[15.569275],\n",
      "       [15.194242]], dtype=float32)]\n",
      "5500 0.00059719477 [array([[ 7.991493, -8.596491],\n",
      "       [-8.449792,  8.910081]], dtype=float32), array([[15.674908],\n",
      "       [15.300581]], dtype=float32)]\n",
      "5600 0.00056534726 [array([[ 8.018848, -8.62449 ],\n",
      "       [-8.477118,  8.937737]], dtype=float32), array([[15.780047],\n",
      "       [15.406411]], dtype=float32)]\n",
      "5700 0.0005352899 [array([[ 8.045903, -8.65218 ],\n",
      "       [-8.504144,  8.965088]], dtype=float32), array([[15.884717],\n",
      "       [15.511765]], dtype=float32)]\n",
      "5800 0.00050699257 [array([[ 8.07267  , -8.67957  ],\n",
      "       [-8.530881 ,  8.9921465]], dtype=float32), array([[15.98895 ],\n",
      "       [15.616667]], dtype=float32)]\n",
      "5900 0.00048027642 [array([[ 8.099155, -8.706672],\n",
      "       [-8.557341,  9.018921]], dtype=float32), array([[16.092764],\n",
      "       [15.721142]], dtype=float32)]\n",
      "6000 0.00045509645 [array([[ 8.125374, -8.733494],\n",
      "       [-8.583534,  9.045429]], dtype=float32), array([[16.19618 ],\n",
      "       [15.825219]], dtype=float32)]\n",
      "6100 0.00043131848 [array([[ 8.151329, -8.760049],\n",
      "       [-8.60947 ,  9.071665]], dtype=float32), array([[16.299238],\n",
      "       [15.928915]], dtype=float32)]\n",
      "6200 0.00040891254 [array([[ 8.177038, -8.786348],\n",
      "       [-8.635155,  9.097654]], dtype=float32), array([[16.401945],\n",
      "       [16.03224 ]], dtype=float32)]\n",
      "6300 0.00038768476 [array([[ 8.202503, -8.812394],\n",
      "       [-8.660605,  9.123399]], dtype=float32), array([[16.504309],\n",
      "       [16.135246]], dtype=float32)]\n",
      "6400 0.0003676649 [array([[ 8.227735, -8.838202],\n",
      "       [-8.685819,  9.148904]], dtype=float32), array([[16.606369],\n",
      "       [16.237938]], dtype=float32)]\n",
      "6500 0.00034874846 [array([[ 8.252738, -8.863772],\n",
      "       [-8.710809,  9.174183]], dtype=float32), array([[16.708132],\n",
      "       [16.340311]], dtype=float32)]\n",
      "6600 0.00033083116 [array([[ 8.27753  , -8.889124 ],\n",
      "       [-8.735586 ,  9.1992445]], dtype=float32), array([[16.809645],\n",
      "       [16.442425]], dtype=float32)]\n",
      "6700 0.00031388304 [array([[ 8.30211 , -8.914255],\n",
      "       [-8.760155,  9.224084]], dtype=float32), array([[16.910868],\n",
      "       [16.544245]], dtype=float32)]\n",
      "6800 0.00029785934 [array([[ 8.326485, -8.939171],\n",
      "       [-8.784514,  9.248717]], dtype=float32), array([[17.011858],\n",
      "       [16.645817]], dtype=float32)]\n",
      "6900 0.0002826855 [array([[ 8.3506565, -8.963882 ],\n",
      "       [-8.808678 ,  9.2731495]], dtype=float32), array([[17.112621],\n",
      "       [16.747158]], dtype=float32)]\n",
      "7000 0.0002683317 [array([[ 8.374637, -8.988395],\n",
      "       [-8.83265 ,  9.297393]], dtype=float32), array([[17.213171],\n",
      "       [16.848274]], dtype=float32)]\n",
      "7100 0.00025473826 [array([[ 8.398429, -9.012715],\n",
      "       [-8.856439,  9.321448]], dtype=float32), array([[17.313494],\n",
      "       [16.949194]], dtype=float32)]\n",
      "7200 0.00024184554 [array([[ 8.422035, -9.036848],\n",
      "       [-8.880043,  9.345316]], dtype=float32), array([[17.41363 ],\n",
      "       [17.049894]], dtype=float32)]\n",
      "7300 0.0002296386 [array([[ 8.445466, -9.060798],\n",
      "       [-8.90347 ,  9.369008]], dtype=float32), array([[17.513575],\n",
      "       [17.15041 ]], dtype=float32)]\n",
      "7400 0.00021810248 [array([[ 8.468724, -9.084571],\n",
      "       [-8.926726,  9.392517]], dtype=float32), array([[17.613344],\n",
      "       [17.250736]], dtype=float32)]\n",
      "7500 0.00020710306 [array([[ 8.491817 , -9.1081705],\n",
      "       [-8.949819 ,  9.415861 ]], dtype=float32), array([[17.71295 ],\n",
      "       [17.350893]], dtype=float32)]\n",
      "7600 0.00019672974 [array([[ 8.514756, -9.131594],\n",
      "       [-8.97275 ,  9.439036]], dtype=float32), array([[17.812443],\n",
      "       [17.450882]], dtype=float32)]\n",
      "7700 0.00018689307 [array([[ 8.537529, -9.154857],\n",
      "       [-8.995517,  9.462054]], dtype=float32), array([[17.911798],\n",
      "       [17.55073 ]], dtype=float32)]\n",
      "7800 0.00017753342 [array([[ 8.560148, -9.177964],\n",
      "       [-9.018139,  9.484902]], dtype=float32), array([[18.01098],\n",
      "       [17.65045]], dtype=float32)]\n",
      "7900 0.00016868059 [array([[ 8.58261 , -9.200906],\n",
      "       [-9.040603,  9.507606]], dtype=float32), array([[18.110043],\n",
      "       [17.750013]], dtype=float32)]\n",
      "8000 0.00016026004 [array([[ 8.604927, -9.223698],\n",
      "       [-9.062923,  9.530157]], dtype=float32), array([[18.209024],\n",
      "       [17.849438]], dtype=float32)]\n",
      "8100 0.00015233137 [array([[ 8.627097, -9.246344],\n",
      "       [-9.085099,  9.552573]], dtype=float32), array([[18.307825],\n",
      "       [17.94881 ]], dtype=float32)]\n",
      "8200 0.00014473063 [array([[ 8.649122, -9.26884 ],\n",
      "       [-9.107138,  9.57484 ]], dtype=float32), array([[18.40655 ],\n",
      "       [18.048016]], dtype=float32)]\n",
      "8300 0.00013754726 [array([[ 8.671009, -9.291199],\n",
      "       [-9.129032,  9.596966]], dtype=float32), array([[18.50516 ],\n",
      "       [18.147177]], dtype=float32)]\n",
      "8400 0.0001307365 [array([[ 8.692767, -9.313413],\n",
      "       [-9.150804,  9.618952]], dtype=float32), array([[18.60369 ],\n",
      "       [18.246168]], dtype=float32)]\n",
      "8500 0.00012426857 [array([[ 8.714383, -9.335491],\n",
      "       [-9.172426,  9.640811]], dtype=float32), array([[18.702108],\n",
      "       [18.34514 ]], dtype=float32)]\n",
      "8600 0.00011811364 [array([[ 8.735879, -9.357439],\n",
      "       [-9.193929,  9.662524]], dtype=float32), array([[18.800495],\n",
      "       [18.443941]], dtype=float32)]\n",
      "8700 0.00011228661 [array([[ 8.757246, -9.379246],\n",
      "       [-9.21531 ,  9.684117]], dtype=float32), array([[18.898724],\n",
      "       [18.542742]], dtype=float32)]\n",
      "8800 0.00010675766 [array([[ 8.778482, -9.400931],\n",
      "       [-9.236554,  9.705579]], dtype=float32), array([[18.996952],\n",
      "       [18.641373]], dtype=float32)]\n",
      "8900 0.000101482095 [array([[ 8.799601, -9.422488],\n",
      "       [-9.257682,  9.726914]], dtype=float32), array([[19.09508 ],\n",
      "       [18.739983]], dtype=float32)]\n",
      "9000 9.648972e-05 [array([[ 8.820603, -9.443914],\n",
      "       [-9.278695,  9.748132]], dtype=float32), array([[19.193117],\n",
      "       [18.838554]], dtype=float32)]\n",
      "9100 9.17507e-05 [array([[ 8.841476, -9.465224],\n",
      "       [-9.29959 ,  9.769236]], dtype=float32), array([[19.291155],\n",
      "       [18.936974]], dtype=float32)]\n",
      "9200 8.723523e-05 [array([[ 8.862236, -9.486419],\n",
      "       [-9.320361,  9.790216]], dtype=float32), array([[19.389118],\n",
      "       [19.035393]], dtype=float32)]\n",
      "9300 8.292843e-05 [array([[ 8.882884, -9.507487],\n",
      "       [-9.341022,  9.811074]], dtype=float32), array([[19.486965],\n",
      "       [19.133812]], dtype=float32)]\n",
      "9400 7.886008e-05 [array([[ 8.903426, -9.528439],\n",
      "       [-9.361573,  9.831823]], dtype=float32), array([[19.584812],\n",
      "       [19.232052]], dtype=float32)]\n",
      "9500 7.498548e-05 [array([[ 8.923856, -9.549279],\n",
      "       [-9.382017,  9.852462]], dtype=float32), array([[19.68266],\n",
      "       [19.33028]], dtype=float32)]\n",
      "9600 7.133442e-05 [array([[ 8.944176, -9.57001 ],\n",
      "       [-9.402355,  9.87299 ]], dtype=float32), array([[19.780436],\n",
      "       [19.428509]], dtype=float32)]\n",
      "9700 6.7817506e-05 [array([[ 8.964386 , -9.590632 ],\n",
      "       [-9.422586 ,  9.8934145]], dtype=float32), array([[19.878092],\n",
      "       [19.52673 ]], dtype=float32)]\n",
      "9800 6.450922e-05 [array([[ 8.98449 , -9.611148],\n",
      "       [-9.442713,  9.913729]], dtype=float32), array([[19.975748],\n",
      "       [19.624792]], dtype=float32)]\n",
      "9900 6.136488e-05 [array([[ 9.004492, -9.631549],\n",
      "       [-9.462732,  9.933935]], dtype=float32), array([[20.073404],\n",
      "       [19.72283 ]], dtype=float32)]\n",
      "10000 5.8339763e-05 [array([[ 9.024394, -9.651845],\n",
      "       [-9.482652,  9.95404 ]], dtype=float32), array([[20.17106 ],\n",
      "       [19.820868]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[6.1310318e-05]\n",
      " [9.9993694e-01]\n",
      " [9.9995077e-01]\n",
      " [5.9751477e-05]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x-input')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y-input')\n",
    "\n",
    "with tf.name_scope(\"layer1\"): # tensor 그래프를 정리해서 보여준다.\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "with tf.name_scope(\"cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                           tf.log(1 - hypothesis))\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "accuracy_summ = tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # tensorboard --logdir=./logs/xor_logs\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "    writer.add_graph(sess.graph)  # Show the graph\n",
    "\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        summary, _ = sess.run([merged_summary, train], feed_dict={X: x_data, Y: y_data})\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}), sess.run([W1, W2]))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple runs를 tensorboard를 통해서 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tensorboard --logdir=./logs/xor_logs\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
    "##### tensorboard --logdir=./logs/xor_logs_r0_01\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "> 위에 처럼 저장되어 있다면 tensorboard --logdir=./logs 와 같이 상위 디렉토리로 실행하면 모든 log들을 tensorboard에 보여줌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
