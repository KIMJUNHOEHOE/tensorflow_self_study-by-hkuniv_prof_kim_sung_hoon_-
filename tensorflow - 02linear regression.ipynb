{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traning data, test data<br>\n",
    "y = ax+b<br>\n",
    "cost function<br>\n",
    "실제 데이터와 가설로 세운 선형과 오차가 얼마나 나는지 계산<br>\n",
    "오차는 보통 차이의 제곱으로 계산<br>\n",
    "cost function을 최소화 하는 a,b값을 찾는 것이 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3] # 우리가 입력할 값\n",
    "y_train = [1,2,3] # 실제 값\n",
    "\n",
    "# trainable variable - tensorflow가 학습하는 과정에서 값을 바꾼다\n",
    "# rank가 1인(1차원인) variable\n",
    "W = tf.Variable(tf.random_normal([1]), name ='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name ='bias')\n",
    "# our hypothesis xw+b\n",
    "hypothesis = x_train*W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "t = [1.,2.,3.,4.]\n",
    "sess.run(tf.reduce_mean(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimiaze cost function\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer()) # tensor의 변수 전체 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.410204 [-0.1206751] [0.6373151]\n",
      "200 0.049129825 [0.7425645] [0.5852116]\n",
      "400 0.018760169 [0.8409204] [0.3616253]\n",
      "600 0.0071635568 [0.90169847] [0.22346252]\n",
      "800 0.0027353913 [0.9392558] [0.13808616]\n",
      "1000 0.0010445077 [0.96246374] [0.08532882]\n",
      "1200 0.00039884433 [0.9768049] [0.05272795]\n",
      "1400 0.0001522968 [0.9856669] [0.03258259]\n",
      "1600 5.815418e-05 [0.9911431] [0.02013393]\n",
      "1800 2.2205626e-05 [0.9945269] [0.01244155]\n",
      "2000 8.479116e-06 [0.9966179] [0.00768817]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders - session을 실행할 때 값을 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.3993306 [2.1543937] [-0.4651283]\n",
      "200 0.036578562 [1.2215971] [-0.50374216]\n",
      "400 0.013967452 [1.1369333] [-0.3112817]\n",
      "600 0.005333426 [1.0846163] [-0.19235288]\n",
      "800 0.002036567 [1.0522877] [-0.11886235]\n",
      "1000 0.0007776601 [1.0323107] [-0.07344978]\n",
      "1200 0.00029695054 [1.019966] [-0.04538764]\n",
      "1400 0.000113388814 [1.0123378] [-0.02804655]\n",
      "1600 4.3298427e-05 [1.007624] [-0.01733116]\n",
      "1800 1.6533531e-05 [1.0047113] [-0.01070972]\n",
      "2000 6.314063e-06 [1.0029113] [-0.00661815]\n"
     ]
    }
   ],
   "source": [
    "# Try to find value for W and b to compute y_data = x_data * W + b  \n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let's TensorFlow figure it out \n",
    "W = tf.Variable(tf.random_normal([1]), name='weight') # 1차원인 random_normal값\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "#### Now we can use X and Y in place of x_data and y_data\n",
    "#### placeholders for a tensor that will be always fed using feed_dict\n",
    "#### See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Out hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):# 원화는 다음 행과 연결된다는 의미임\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                 feed_dict={X: [1, 2, 3], Y: [1, 2, 3]})\n",
    "    if step % 200 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.007939]\n",
      "[1.4977489 2.5006602 3.5035713 4.506483  5.007939 ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X: [5.]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5,2.5,3.5,4.5,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2053663 [1.0686679] [0.01533953]\n",
      "200 0.049682893 [1.1442219] [0.57931364]\n",
      "400 0.012819687 [1.07326] [0.8355084]\n",
      "600 0.0033078832 [1.0372137] [0.9656468]\n",
      "800 0.0008535385 [1.0189033] [1.0317528]\n",
      "1000 0.0002202394 [1.0096022] [1.0653328]\n",
      "1200 5.6825018e-05 [1.0048774] [1.0823905]\n",
      "1400 1.4662392e-05 [1.0024776] [1.091055]\n",
      "1600 3.7832438e-06 [1.0012585] [1.0954562]\n",
      "1800 9.766156e-07 [1.0006396] [1.0976914]\n",
      "2000 2.5229406e-07 [1.0003251] [1.0988266]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost,W,b,train],\n",
    "                                        feed_dict={X:[1,2,3,4,5], Y:[2.1,3.1,4.1,5.1,6.1]})\n",
    "    if step%200 == 0:\n",
    "        print(step,cost_val,W_val,b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1004524]\n",
      "[3.5996394]\n",
      "[2.5993142 4.599964 ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
